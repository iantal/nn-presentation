{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepdish in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: numpy in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from deepdish) (1.17.2)\n",
      "Requirement already satisfied: scipy in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from deepdish) (1.4.1)\n",
      "Requirement already satisfied: tables in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from deepdish) (3.5.2)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from tables->deepdish) (2.7.0)\n",
      "Requirement already satisfied: mock>=2.0 in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from tables->deepdish) (3.0.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/miki/opt/anaconda3/lib/python3.7/site-packages (from tables->deepdish) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install deepdish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "\n",
    "import deepdish as dd\n",
    "import deepdish.io as ddio\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import time\n",
    "\n",
    "from glob import glob\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from wfdb import rdrecord, rdann\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, add, Dropout, MaxPooling1D, Activation, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is provided by\n",
    "https://physionet.org/physiobank/database/html/mitdbdir/mitdbdir.htm\n",
    "\n",
    "The recordings were digitized at 360 samples per second per channel with 11-bit resolution over a 10 mV range.\n",
    "Two or more cardiologists independently annotated each record; disagreements were resolved to obtain the computer-readable\n",
    "reference annotations for each beat (approximately 110,000 annotations in all) included with the database.\n",
    "\n",
    "    Code\t\tDescription\n",
    "    N\t\tNormal beat (displayed as . by the PhysioBank ATM, LightWAVE, pschart, and psfd)\n",
    "    L\t\tLeft bundle branch block beat\n",
    "    R\t\tRight bundle branch block beat\n",
    "    B\t\tBundle branch block beat (unspecified)\n",
    "    A\t\tAtrial premature beat\n",
    "    a\t\tAberrated atrial premature beat\n",
    "    J\t\tNodal (junctional) premature beat\n",
    "    S\t\tSupraventricular premature or ectopic beat (atrial or nodal)\n",
    "    V\t\tPremature ventricular contraction\n",
    "    r\t\tR-on-T premature ventricular contraction\n",
    "    F\t\tFusion of ventricular and normal beat\n",
    "    e\t\tAtrial escape beat\n",
    "    j\t\tNodal (junctional) escape beat\n",
    "    n\t\tSupraventricular escape beat (atrial or nodal)\n",
    "    E\t\tVentricular escape beat\n",
    "    /\t\tPaced beat\n",
    "    f\t\tFusion of paced and normal beat\n",
    "    Q\t\tUnclassifiable beat\n",
    "    ?\t\tBeat not classified during learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"mitdb\"):\n",
    "    print('You already have the data.')\n",
    "else:\n",
    "    wfdb.dl_database('mitdb', 'mitdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records():\n",
    "    paths = glob('mitdb/*.atr')\n",
    "    paths = [path[:-4].rsplit(\"/\", 1)[1] for path in paths]\n",
    "    paths.sort()\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 256\n",
    "features = ['MLII', 'V1', 'V2', 'V4', 'V5']  # signal names\n",
    "nums = get_records()                         # file names without extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    test_set = ['101', '105', '114', '118', '124', '201', '210', '217']\n",
    "    train_set = [x for x in nums if x not in test_set]\n",
    "    data_saver(train_set, 'mitdb/train.hdf5', 'mitdb/trainlabel.hdf5')\n",
    "    data_saver(test_set, 'mitdb/test.hdf5', 'mitdb/testlabel.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_saver(dataset, dataset_name, labels_name):\n",
    "    classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "    classes_length = len(classes)  # used for creating masks\n",
    "    datadict, data_label = dict(), dict()\n",
    "\n",
    "    \"\"\"\n",
    "    {\n",
    "        \"N\": [],\n",
    "        \"V\": [],\n",
    "        \"/\": [],\n",
    "        \"A\": [],\n",
    "        \"F\": [],\n",
    "        \"~\": []\n",
    "    }\n",
    "    \"\"\"\n",
    "    for feature in features:\n",
    "        datadict[feature] = list()\n",
    "        data_label[feature] = list()\n",
    "\n",
    "    data_process(dataset, classes, datadict, data_label)\n",
    "    add_noise_to_dataset(classes_length, data_label, datadict)\n",
    "\n",
    "    dd.io.save(dataset_name, datadict)\n",
    "    dd.io.save(labels_name, data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset, classes, datadict, data_label):\n",
    "    for num in tqdm(dataset):\n",
    "        record = rdrecord('mitdb/' + num, smooth_frames=True)\n",
    "\n",
    "        signals_channel_0 = preprocessing.scale(np.nan_to_num(record.p_signal[:, 0])).tolist()\n",
    "        signals_channel_1 = preprocessing.scale(np.nan_to_num(record.p_signal[:, 1])).tolist()\n",
    "\n",
    "        peaks, _ = find_peaks(signals_channel_0, distance=150)\n",
    "\n",
    "        feature0, feature1 = record.sig_name[0], record.sig_name[1]\n",
    "\n",
    "        # skip the first and last peaks to have enough range of the sample\n",
    "        for peak in peaks[1:-1]:\n",
    "            start, end = peak - INPUT_SIZE // 2, peak + INPUT_SIZE // 2\n",
    "            annotation = rdann('mitdb/' + num, extension='atr', sampfrom=start, sampto=end, return_label_elements=['symbol'])\n",
    "\n",
    "            # remove some of \"N\" which breaks the balance of dataset\n",
    "            if len(annotation.symbol) == 1 and (annotation.symbol[0] in classes) and (annotation.symbol[0] != \"N\" or np.random.random() < 0.15):\n",
    "                y = [0] * len(classes)\n",
    "                y[classes.index(annotation.symbol[0])] = 1\n",
    "                data_label[feature0].append(y)\n",
    "                data_label[feature1].append(y)\n",
    "                datadict[feature0].append(signals_channel_0[start:end])\n",
    "                datadict[feature1].append(signals_channel_1[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_dataset(classes_length, data_label, datadict):\n",
    "        noises = add_noise()\n",
    "        for feature in [\"MLII\", \"V1\"]:\n",
    "            d = np.array(datadict[feature])\n",
    "            if len(d) > 15 * 10 ** 3:\n",
    "                n = np.array(noises[\"trainset\"])\n",
    "            else:\n",
    "                n = np.array(noises[\"testset\"])\n",
    "\n",
    "            datadict[feature] = np.concatenate((d, n))\n",
    "            size, _ = n.shape\n",
    "            l = np.array(data_label[feature])\n",
    "            noise_label = [0] * classes_length\n",
    "            noise_label[-1] = 1\n",
    "\n",
    "            noise_label = np.array([noise_label] * size)\n",
    "            data_label[feature] = np.concatenate((l, noise_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise():\n",
    "    noises = dict()\n",
    "    noises[\"trainset\"] = list()\n",
    "    noises[\"testset\"] = list()\n",
    "\n",
    "    \n",
    "    testlabel = list(csv.reader(open('training2017/REFERENCE.csv')))\n",
    "    \n",
    "    for i, label in enumerate(testlabel):\n",
    "        if label[1] == '~':\n",
    "            filename = 'training2017/' + label[0] + '.mat'\n",
    "            from scipy.io import loadmat\n",
    "            noise = loadmat(filename)\n",
    "            noise = noise['val']\n",
    "            _, size = noise.shape\n",
    "            noise = noise.reshape(size, )\n",
    "            noise = np.nan_to_num(noise)  # removing NaNs and Infs\n",
    "            from scipy.signal import resample\n",
    "            noise = resample(noise, int(\n",
    "                len(noise) * 360 / 300))  # resample to match the data sampling rate 360(mit), 300(cinc)\n",
    "            from sklearn import preprocessing\n",
    "            noise = preprocessing.scale(noise)\n",
    "            noise = noise / 1000 * 6  # rough normalize, to be improved\n",
    "            from scipy.signal import find_peaks\n",
    "            peaks, _ = find_peaks(noise, distance=150)\n",
    "            choices = 10  # 256*10 from 9000\n",
    "            picked_peaks = np.random.choice(peaks, choices, replace=False)\n",
    "            for j, peak in enumerate(picked_peaks):\n",
    "                if peak > INPUT_SIZE // 2 and peak < len(noise) - INPUT_SIZE // 2:\n",
    "                    start, end = peak - INPUT_SIZE // 2, peak + INPUT_SIZE // 2\n",
    "                    if i > len(testlabel) / 6:\n",
    "                        noises[\"trainset\"].append(noise[start:end].tolist())\n",
    "                    else:\n",
    "                        noises[\"testset\"].append(noise[start:end].tolist())\n",
    "    return noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(input_size, feature):\n",
    "    trainData = ddio.load('mitdb/train.hdf5')\n",
    "    testlabelData = ddio.load('mitdb/trainlabel.hdf5')\n",
    "    X = np.float32(trainData[feature])\n",
    "    print(\"[+] X:\")\n",
    "    print(X)\n",
    "    y = np.float32(testlabelData[feature])\n",
    "    print(\"[+] y:\")\n",
    "    print(y)\n",
    "    att = np.concatenate((X, y), axis=1)\n",
    "    print(\"[+] Att:\")\n",
    "    print(att)\n",
    "    np.random.shuffle(att)\n",
    "    X, y = att[:, :input_size], att[:, input_size:]\n",
    "    valData = ddio.load('mitdb/test.hdf5')\n",
    "    vallabelData = ddio.load('mitdb/testlabel.hdf5')\n",
    "    Xval = np.float32(valData[feature])\n",
    "    yval = np.float32(vallabelData[feature])\n",
    "    return (X, y, Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_recursive(path):\n",
    "    if path == \"\":\n",
    "        return\n",
    "    sub_path = os.path.dirname(path)\n",
    "    if not os.path.exists(sub_path):\n",
    "        mkdir_recursive(sub_path)\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Creating directory \" + path)\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PR_ROC_curves(ytrue, ypred, classes, ypred_mat):\n",
    "    ybool = ypred == ytrue\n",
    "    f, ax = plt.subplots(3, 4, figsize=(10, 10))\n",
    "    ax = [a for i in ax for a in i]\n",
    "\n",
    "    e = -1\n",
    "    for c in classes:\n",
    "        idx1 = [n for n, x in enumerate(ytrue) if classes[x] == c]\n",
    "        idx2 = [n for n, x in enumerate(ypred) if classes[x] == c]\n",
    "        idx = idx1 + idx2\n",
    "        if idx == []:\n",
    "            continue\n",
    "        bi_ytrue = ytrue[idx]\n",
    "        bi_prob = ypred_mat[idx, :]\n",
    "        bi_ybool = np.array(ybool[idx])\n",
    "        bi_yscore = np.array([bi_prob[x][bi_ytrue[x]] for x in range(len(idx))])\n",
    "        try:\n",
    "            print(\"AUC for {}: {}\".format(c, roc_auc_score(bi_ybool + 0, bi_yscore)))\n",
    "            e += 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "        ppvs, senss, thresholds = precision_recall_curve(bi_ybool, bi_yscore)\n",
    "        cax = ax[2 * e]\n",
    "        cax.plot(ppvs, senss, lw=2, label=\"Model\")\n",
    "        cax.set_xlim(-0.008, 1.05)\n",
    "        cax.set_ylim(0.0, 1.05)\n",
    "        cax.set_title(\"Class {}\".format(c))\n",
    "        cax.set_xlabel('Sensitivity (Recall)')\n",
    "        cax.set_ylabel('PPV (Precision)')\n",
    "        cax.legend(loc=3)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(bi_ybool, bi_yscore)\n",
    "        cax2 = ax[2 * e + 1]\n",
    "        cax2.plot(fpr, tpr, lw=2, label=\"Model\")\n",
    "        cax2.set_xlim(-0.1, 1.)\n",
    "        cax2.set_ylim(0.0, 1.05)\n",
    "        cax2.set_title(\"Class {}\".format(c))\n",
    "        cax2.set_xlabel('1 - Specificity')\n",
    "        cax2.set_ylabel('Sensitivity')\n",
    "        cax2.legend(loc=4)\n",
    "\n",
    "    mkdir_recursive(\"results\")\n",
    "    plt.savefig(\"results/model_prec_recall_and_roc.eps\",\n",
    "                dpi=400,\n",
    "                format='eps',\n",
    "                bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, feature,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    mkdir_recursive('results')\n",
    "    fig.savefig('results/confusionMatrix-mlii.eps', format='eps', dpi=1000)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model, Xval, yval, classes):\n",
    "    model2 = model\n",
    "    model.load_weights('models/MLII-latest.hdf5')\n",
    "    # to combine different trained models. On testing\n",
    "    \n",
    "    ypred_mat = model.predict(Xval)\n",
    "    \n",
    "    ypred_mat = ypred_mat[:, 0]\n",
    "    yval = yval[:, 0]\n",
    "\n",
    "    ytrue = np.argmax(yval, axis=1)\n",
    "    yscore = np.array([ypred_mat[x][ytrue[x]] for x in range(len(yval))])\n",
    "    ypred = np.argmax(ypred_mat, axis=1)\n",
    "    print(classification_report(ytrue, ypred))\n",
    "    plot_confusion_matrix(ytrue, ypred, classes, feature=32, normalize=False)\n",
    "    print(\"F1 score:\", f1_score(ytrue, ypred, average=None))\n",
    "    PR_ROC_curves(ytrue, ypred, classes, ypred_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgModel(object):\n",
    "    def first_convolution_block(self, inputs):\n",
    "        layer = Conv1D(filters=32,\n",
    "                       kernel_size=16,\n",
    "                       padding='same',\n",
    "                       strides=1,\n",
    "                       kernel_initializer='he_normal')(inputs)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "\n",
    "        shortcut = MaxPooling1D(pool_size=1,\n",
    "                                strides=1)(layer)\n",
    "\n",
    "        layer = Conv1D(filters=32,\n",
    "                       kernel_size=16,\n",
    "                       padding='same',\n",
    "                       strides=1,\n",
    "                       kernel_initializer='he_normal')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = Dropout(0.2)(layer)\n",
    "        layer = Conv1D(filters=32,\n",
    "                       kernel_size=16,\n",
    "                       padding='same',\n",
    "                       strides=1,\n",
    "                       kernel_initializer='he_normal')(layer)\n",
    "        return add([shortcut, layer])\n",
    "\n",
    "    def main_loop_blocks(self, layer):\n",
    "        filter_length = 32\n",
    "        n_blocks = 15\n",
    "        for block_index in range(n_blocks):\n",
    "            def zeropad(x):\n",
    "                y = K.zeros_like(x)\n",
    "                return K.concatenate([x, y], axis=2)\n",
    "\n",
    "            def zeropad_output_shape(input_shape):\n",
    "                shape = list(input_shape)\n",
    "                assert len(shape) == 3\n",
    "                shape[2] *= 2\n",
    "                return tuple(shape)\n",
    "\n",
    "            subsample_length = 2 if block_index % 2 == 0 else 1\n",
    "            shortcut = MaxPooling1D(pool_size=subsample_length)(layer)\n",
    "\n",
    "            # 5 is chosen instead of 4 from the original model\n",
    "            if block_index % 4 == 0 and block_index > 0:\n",
    "                # double size of the network and match the shapes of both branches\n",
    "                shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
    "                filter_length *= 2\n",
    "\n",
    "            layer = BatchNormalization()(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Conv1D(filters=filter_length,\n",
    "                           kernel_size=16,\n",
    "                           padding='same',\n",
    "                           strides=subsample_length,\n",
    "                           kernel_initializer='he_normal')(layer)\n",
    "            layer = BatchNormalization()(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Dropout(0.2)(layer)\n",
    "            layer = Conv1D(filters=filter_length,\n",
    "                           kernel_size=16,\n",
    "                           padding='same',\n",
    "                           strides=1,\n",
    "                           kernel_initializer='he_normal')(layer)\n",
    "            layer = add([shortcut, layer])\n",
    "        return layer\n",
    "\n",
    "    def output_block(self, layer, inputs):\n",
    "        classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "        len_classes = len(classes)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        outputs = TimeDistributed(Dense(len_classes, activation='softmax'))(layer)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def create_network(self):\n",
    "        inputs = Input(shape=(256, 1), name='input')\n",
    "        layer = self.first_convolution_block(inputs)\n",
    "        layer = self.main_loop_blocks(layer)\n",
    "        return self.output_block(layer, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(object):\n",
    "    def __init__(self):\n",
    "        mkdir_recursive('models')\n",
    "        self.xv = None\n",
    "        self.yv = None\n",
    "        self.classes = None\n",
    "        self.model = None\n",
    "\n",
    "    @staticmethod\n",
    "    def run(X, y, Xval=None, yval=None):\n",
    "        classes = ['N', 'V', '/', 'A', 'F', '~']\n",
    "\n",
    "        x = np.expand_dims(X, axis=2)\n",
    "\n",
    "        \n",
    "        xv = np.expand_dims(Xval, axis=2)\n",
    "        (m, n) = y.shape\n",
    "\n",
    "        print(\"-----\")\n",
    "        print(m)\n",
    "        print(n)\n",
    "        print(\"-----\")\n",
    "\n",
    "        y = y.reshape((m, 1, n))\n",
    "        (mvl, nvl) = yval.shape\n",
    "        yv = yval.reshape((mvl, 1, nvl))\n",
    "\n",
    "        model = EcgModel().create_network()\n",
    "\n",
    "        callbacks = [\n",
    "            ReduceLROnPlateau(factor=0.5, patience=3, min_lr=0.01, verbose=1),\n",
    "            TensorBoard(log_dir='./logs', histogram_freq=10, write_graph=True, write_grads=False, write_images=True),\n",
    "            ModelCheckpoint('models/{}-latest.hdf5'.format(\"MLII\"), monitor='val_loss', save_best_only=False, verbose=1, period=10)\n",
    "        ]\n",
    "\n",
    "        if model is None:\n",
    "            print(\"none\")\n",
    "\n",
    "        H = model.fit(x, y,\n",
    "                  validation_data=(xv, yv),\n",
    "                  epochs=50,\n",
    "                  batch_size=256,\n",
    "                  callbacks=callbacks,\n",
    "                  initial_epoch=0)\n",
    "        \n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(H.history['accuracy'])\n",
    "        plt.plot(H.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.plot(H.history['loss'])\n",
    "        plt.plot(H.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "        return (model, xv, yv, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] X:\n",
      "[[-2.7795628e-01 -2.5207630e-01 -3.0383626e-01 ... -1.9156480e-02\n",
      "   5.8483455e-02  1.1024341e-01]\n",
      " [-4.0735614e-01 -3.8147619e-01 -3.2971624e-01 ... -7.0916437e-02\n",
      "  -4.5036457e-02 -1.9156480e-02]\n",
      " [ 1.1024341e-01  1.6200337e-01  1.3612339e-01 ...  1.1024341e-01\n",
      "   1.1024341e-01  1.1024341e-01]\n",
      " ...\n",
      " [ 3.4534474e-04  3.6154487e-04  3.7135973e-04 ...  7.1554905e-04\n",
      "   7.2404329e-04  7.3409878e-04]\n",
      " [ 2.6782041e-03  4.2591202e-03  5.8382354e-03 ...  4.3132114e-03\n",
      "   4.3793935e-03  2.8295030e-03]\n",
      " [-9.7649114e-04 -1.0027420e-03 -1.0283404e-03 ... -1.9492710e-03\n",
      "  -2.1063504e-03 -2.1766378e-03]]\n",
      "[+] y:\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[+] Att:\n",
      "[[-2.7795628e-01 -2.5207630e-01 -3.0383626e-01 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [-4.0735614e-01 -3.8147619e-01 -3.2971624e-01 ...  1.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 1.1024341e-01  1.6200337e-01  1.3612339e-01 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " ...\n",
      " [ 3.4534474e-04  3.6154487e-04  3.7135973e-04 ...  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [ 2.6782041e-03  4.2591202e-03  5.8382354e-03 ...  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00]\n",
      " [-9.7649114e-04 -1.0027420e-03 -1.0283404e-03 ...  0.0000000e+00\n",
      "   0.0000000e+00  1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "(X, y, Xval, yval) = loaddata(256, \"MLII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "22817\n",
      "6\n",
      "-----\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 256, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 256, 32)      544         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 32)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 256, 32)      16416       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 32)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 32)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 256, 32)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 256, 32)      16416       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256, 32)      0           max_pooling1d[0][0]              \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 32)      128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 32)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 128, 32)      16416       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 32)      128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 32)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 32)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 128, 32)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 128, 32)      16416       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 32)      0           max_pooling1d_1[0][0]            \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 32)      128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 128, 32)      16416       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 32)      128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 128, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 128, 32)      16416       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 32)      0           max_pooling1d_2[0][0]            \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 32)      128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 64, 32)       16416       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 32)       128         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 32)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 32)       0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 32)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 32)       16416       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 32)       0           max_pooling1d_3[0][0]            \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 32)       128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 32)       0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 64, 32)       16416       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 32)       128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 32)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 32)       0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 64, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 32)       16416       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 32)       0           max_pooling1d_4[0][0]            \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 32)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 32)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 32, 64)       32832       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 64)       256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 64)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 32, 32)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 32, 64)       0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 32, 64)       65600       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 64)       0           lambda[0][0]                     \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 64)       256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 64)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 32, 64)       65600       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 64)       256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 64)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 64)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 32, 64)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 32, 64)       65600       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 64)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 64)       256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 64)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 16, 64)       65600       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 64)       256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 64)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 64)       0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 16, 64)       0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 16, 64)       65600       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 64)       0           max_pooling1d_7[0][0]            \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 64)       256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 64)       0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 16, 64)       65600       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 64)       256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 64)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 64)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 16, 64)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16, 64)       65600       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 64)       0           max_pooling1d_8[0][0]            \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 64)       256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 64)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 8, 128)       131200      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 128)       512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 128)       0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 8, 64)        0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 128)       0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 128)       0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 8, 128)       262272      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 128)       0           lambda_1[0][0]                   \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 128)       512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 128)       0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 8, 128)       262272      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 128)       512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 128)       0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 128)       0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 8, 128)       0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 8, 128)       262272      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 128)       0           max_pooling1d_10[0][0]           \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 128)       512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 128)       0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 4, 128)       262272      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 128)       512         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 128)       0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 4, 128)       0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 4, 128)       0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 4, 128)       262272      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 128)       0           max_pooling1d_11[0][0]           \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 128)       512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 128)       0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 4, 128)       262272      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 128)       512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 128)       0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 4, 128)       0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 4, 128)       0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 4, 128)       262272      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 128)       0           max_pooling1d_12[0][0]           \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 128)       512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 128)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 2, 256)       524544      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 256)       1024        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 256)       0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 2, 128)       0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 2, 256)       0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2, 256)       0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 2, 256)       1048832     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 256)       0           lambda_2[0][0]                   \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 256)       1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 256)       0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 2, 256)       1048832     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2, 256)       1024        conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 256)       0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 2, 256)       0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 2, 256)       0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 2, 256)       1048832     dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 256)       0           max_pooling1d_14[0][0]           \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2, 256)       1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 256)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1, 256)       1048832     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1, 256)       1024        conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1, 256)       0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1, 256)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 1, 256)       0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1, 256)       1048832     dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 256)       0           max_pooling1d_15[0][0]           \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1, 256)       1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 256)       0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 1, 6)         1542        activation_32[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,407,782\n",
      "Trainable params: 8,400,934\n",
      "Non-trainable params: 6,848\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 22817 samples, validate on 4520 samples\n",
      "Epoch 1/50\n",
      "22817/22817 [==============================] - 172s 8ms/sample - loss: 0.3204 - accuracy: 0.8949 - val_loss: 5.2482 - val_accuracy: 0.2692\n",
      "Epoch 2/50\n",
      "22817/22817 [==============================] - 160s 7ms/sample - loss: 0.1235 - accuracy: 0.9608 - val_loss: 0.9424 - val_accuracy: 0.6803\n",
      "Epoch 3/50\n",
      "22817/22817 [==============================] - 157s 7ms/sample - loss: 0.0865 - accuracy: 0.9717 - val_loss: 1.3062 - val_accuracy: 0.6270\n",
      "Epoch 4/50\n",
      "22817/22817 [==============================] - 188s 8ms/sample - loss: 0.0788 - accuracy: 0.9732 - val_loss: 0.5295 - val_accuracy: 0.8637\n",
      "Epoch 5/50\n",
      "22817/22817 [==============================] - 189s 8ms/sample - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.4694 - val_accuracy: 0.8677\n",
      "Epoch 6/50\n",
      "22817/22817 [==============================] - 180s 8ms/sample - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.8503 - val_accuracy: 0.7423\n",
      "Epoch 7/50\n",
      "22817/22817 [==============================] - 182s 8ms/sample - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.5099 - val_accuracy: 0.8613\n",
      "Epoch 8/50\n",
      "22817/22817 [==============================] - 168s 7ms/sample - loss: 0.0464 - accuracy: 0.9843 - val_loss: 0.4782 - val_accuracy: 0.8582\n",
      "Epoch 9/50\n",
      "22817/22817 [==============================] - 187s 8ms/sample - loss: 0.0413 - accuracy: 0.9851 - val_loss: 0.5982 - val_accuracy: 0.8560\n",
      "Epoch 10/50\n",
      "22784/22817 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9860\n",
      "Epoch 00010: saving model to models/MLII-latest.hdf5\n",
      "22817/22817 [==============================] - 183s 8ms/sample - loss: 0.0405 - accuracy: 0.9860 - val_loss: 0.5608 - val_accuracy: 0.8668\n",
      "Epoch 11/50\n",
      "22817/22817 [==============================] - 179s 8ms/sample - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.4530 - val_accuracy: 0.8799\n",
      "Epoch 12/50\n",
      "22817/22817 [==============================] - 177s 8ms/sample - loss: 0.0468 - accuracy: 0.9843 - val_loss: 0.6445 - val_accuracy: 0.8142\n",
      "Epoch 13/50\n",
      "22817/22817 [==============================] - 194s 9ms/sample - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.5670 - val_accuracy: 0.8325\n",
      "Epoch 14/50\n",
      "22817/22817 [==============================] - 188s 8ms/sample - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.5138 - val_accuracy: 0.8650\n",
      "Epoch 15/50\n",
      "22817/22817 [==============================] - 203s 9ms/sample - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.5150 - val_accuracy: 0.8796\n",
      "Epoch 16/50\n",
      "22817/22817 [==============================] - 171s 8ms/sample - loss: 0.0289 - accuracy: 0.9901 - val_loss: 0.6486 - val_accuracy: 0.8540\n",
      "Epoch 17/50\n",
      "22817/22817 [==============================] - 174s 8ms/sample - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.7735 - val_accuracy: 0.8051\n",
      "Epoch 18/50\n",
      "22817/22817 [==============================] - 171s 7ms/sample - loss: 0.0227 - accuracy: 0.9918 - val_loss: 0.6484 - val_accuracy: 0.8646\n",
      "Epoch 19/50\n",
      "22817/22817 [==============================] - 1573s 69ms/sample - loss: 0.0262 - accuracy: 0.9904 - val_loss: 0.7344 - val_accuracy: 0.8252\n",
      "Epoch 20/50\n",
      "22784/22817 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9918\n",
      "Epoch 00020: saving model to models/MLII-latest.hdf5\n",
      "22817/22817 [==============================] - 184s 8ms/sample - loss: 0.0216 - accuracy: 0.9917 - val_loss: 0.6716 - val_accuracy: 0.8542\n",
      "Epoch 21/50\n",
      "22817/22817 [==============================] - 173s 8ms/sample - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.6325 - val_accuracy: 0.8279\n",
      "Epoch 22/50\n",
      "22817/22817 [==============================] - 172s 8ms/sample - loss: 0.0198 - accuracy: 0.9926 - val_loss: 1.4006 - val_accuracy: 0.6912\n",
      "Epoch 23/50\n",
      "22817/22817 [==============================] - 161s 7ms/sample - loss: 0.0227 - accuracy: 0.9921 - val_loss: 1.1467 - val_accuracy: 0.7135\n",
      "Epoch 24/50\n",
      "22817/22817 [==============================] - 162s 7ms/sample - loss: 0.0194 - accuracy: 0.9927 - val_loss: 0.5605 - val_accuracy: 0.8606\n",
      "Epoch 25/50\n",
      "22817/22817 [==============================] - 160s 7ms/sample - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.7831 - val_accuracy: 0.8230\n",
      "Epoch 26/50\n",
      "22817/22817 [==============================] - 165s 7ms/sample - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.6488 - val_accuracy: 0.8841\n",
      "Epoch 27/50\n",
      "22817/22817 [==============================] - 166s 7ms/sample - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.6981 - val_accuracy: 0.8757\n",
      "Epoch 28/50\n",
      "22817/22817 [==============================] - 176s 8ms/sample - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.6426 - val_accuracy: 0.8754\n",
      "Epoch 29/50\n",
      "22817/22817 [==============================] - 181s 8ms/sample - loss: 0.0177 - accuracy: 0.9934 - val_loss: 0.7092 - val_accuracy: 0.8560\n",
      "Epoch 30/50\n",
      "22784/22817 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9959\n",
      "Epoch 00030: saving model to models/MLII-latest.hdf5\n",
      "22817/22817 [==============================] - 170s 7ms/sample - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.5756 - val_accuracy: 0.8878\n",
      "Epoch 31/50\n",
      "22817/22817 [==============================] - 175s 8ms/sample - loss: 0.0311 - accuracy: 0.9893 - val_loss: 0.7999 - val_accuracy: 0.7823\n",
      "Epoch 32/50\n",
      "22817/22817 [==============================] - 167s 7ms/sample - loss: 0.0244 - accuracy: 0.9916 - val_loss: 1.0012 - val_accuracy: 0.7429\n",
      "Epoch 33/50\n",
      "22817/22817 [==============================] - 172s 8ms/sample - loss: 0.0146 - accuracy: 0.9943 - val_loss: 1.0986 - val_accuracy: 0.7394\n",
      "Epoch 34/50\n",
      "22817/22817 [==============================] - 169s 7ms/sample - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.7932 - val_accuracy: 0.8018\n",
      "Epoch 35/50\n",
      "22817/22817 [==============================] - 168s 7ms/sample - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.6818 - val_accuracy: 0.8529\n",
      "Epoch 36/50\n",
      "22817/22817 [==============================] - 177s 8ms/sample - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.7461 - val_accuracy: 0.8551\n",
      "Epoch 37/50\n",
      "22817/22817 [==============================] - 175s 8ms/sample - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.7045 - val_accuracy: 0.8507\n",
      "Epoch 38/50\n",
      "22817/22817 [==============================] - 794s 35ms/sample - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.9566 - val_accuracy: 0.7491\n",
      "Epoch 39/50\n",
      "22817/22817 [==============================] - 175s 8ms/sample - loss: 0.0110 - accuracy: 0.9955 - val_loss: 0.7791 - val_accuracy: 0.8159\n",
      "Epoch 40/50\n",
      "22784/22817 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9953\n",
      "Epoch 00040: saving model to models/MLII-latest.hdf5\n",
      "22817/22817 [==============================] - 169s 7ms/sample - loss: 0.0116 - accuracy: 0.9953 - val_loss: 0.8244 - val_accuracy: 0.8381\n",
      "Epoch 41/50\n",
      "22817/22817 [==============================] - 189s 8ms/sample - loss: 0.0116 - accuracy: 0.9954 - val_loss: 1.0602 - val_accuracy: 0.7633\n",
      "Epoch 42/50\n",
      "22817/22817 [==============================] - 211s 9ms/sample - loss: 0.0209 - accuracy: 0.9928 - val_loss: 1.0436 - val_accuracy: 0.7799\n",
      "Epoch 43/50\n",
      "22817/22817 [==============================] - 205s 9ms/sample - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.6903 - val_accuracy: 0.8420\n",
      "Epoch 44/50\n",
      "22817/22817 [==============================] - 185s 8ms/sample - loss: 0.0092 - accuracy: 0.9963 - val_loss: 0.7431 - val_accuracy: 0.8662\n",
      "Epoch 45/50\n",
      "22817/22817 [==============================] - 189s 8ms/sample - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.8611 - val_accuracy: 0.8604\n",
      "Epoch 46/50\n",
      "22817/22817 [==============================] - 198s 9ms/sample - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.5409 - val_accuracy: 0.8863\n",
      "Epoch 47/50\n",
      "22817/22817 [==============================] - 197s 9ms/sample - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.7170 - val_accuracy: 0.8412\n",
      "Epoch 48/50\n",
      "22817/22817 [==============================] - 181s 8ms/sample - loss: 0.0093 - accuracy: 0.9962 - val_loss: 0.8939 - val_accuracy: 0.8396\n",
      "Epoch 49/50\n",
      "22817/22817 [==============================] - 185s 8ms/sample - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.8164 - val_accuracy: 0.8343\n",
      "Epoch 50/50\n",
      "22784/22817 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9967\n",
      "Epoch 00050: saving model to models/MLII-latest.hdf5\n",
      "22817/22817 [==============================] - 177s 8ms/sample - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.8616 - val_accuracy: 0.8398\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.training.Model at 0x7fce88836590>,\n",
       " array([[[-1.75289690e-01],\n",
       "         [-2.32726514e-01],\n",
       "         [-2.32726514e-01],\n",
       "         ...,\n",
       "         [-1.36998460e-01],\n",
       "         [-1.94435298e-01],\n",
       "         [-2.32726514e-01]],\n",
       " \n",
       "        [[-6.34784400e-01],\n",
       "         [-6.15638793e-01],\n",
       "         [-6.15638793e-01],\n",
       "         ...,\n",
       "         [-4.62473869e-01],\n",
       "         [-4.81619477e-01],\n",
       "         [-5.00765085e-01]],\n",
       " \n",
       "        [[-4.12703976e-02],\n",
       "         [ 3.53120491e-02],\n",
       "         [ 3.53120491e-02],\n",
       "         ...,\n",
       "         [-1.17852844e-01],\n",
       "         [-1.94435298e-01],\n",
       "         [-2.32726514e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.08480232e-03],\n",
       "         [-2.19310611e-03],\n",
       "         [-5.84538188e-03],\n",
       "         ...,\n",
       "         [-4.34195041e-04],\n",
       "         [-3.07900045e-04],\n",
       "         [-2.57695472e-04]],\n",
       " \n",
       "        [[-4.04831674e-03],\n",
       "         [-4.05391725e-03],\n",
       "         [-4.08366416e-03],\n",
       "         ...,\n",
       "         [-5.39610861e-03],\n",
       "         [-6.85710739e-03],\n",
       "         [-8.47339723e-03]],\n",
       " \n",
       "        [[-1.46462135e-02],\n",
       "         [-1.46221723e-02],\n",
       "         [-1.46062886e-02],\n",
       "         ...,\n",
       "         [-2.46996933e-04],\n",
       "         [-2.89729884e-04],\n",
       "         [-3.49887472e-04]]], dtype=float32),\n",
       " array([[[1., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[1., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 1.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 1.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 1.]]], dtype=float32),\n",
       " ['N', 'V', '/', 'A', 'F', '~'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train().run(X, y, Xval, yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished in: 10928.806210756302\n"
     ]
    }
   ],
   "source": [
    "print(\"Training finished in: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cincData():\n",
    "    __download_cinc_data()\n",
    "\n",
    "    testlabel = []\n",
    "    __read_data(testlabel)\n",
    "\n",
    "    high = len(testlabel) - 1\n",
    "    num = np.random.randint(1, high)\n",
    "    filename, label = testlabel[num - 1]\n",
    "    filename = 'training2017/' + filename + '.mat'\n",
    "\n",
    "    data = loadmat(filename)\n",
    "    print(\"The record of \" + filename)\n",
    "    data = data['val']\n",
    "    _, size = data.shape\n",
    "    data = data.reshape(size, )\n",
    "    \n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __download_cinc_data():\n",
    "    cmd = \"curl -O https://archive.physionet.org/challenge/2017/training2017.zip\"\n",
    "    os.system(cmd)\n",
    "    os.system(\"unzip training2017.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __read_data(testlabel):\n",
    "    with open('training2017/REFERENCE.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            testlabel.append([row[0], row[1]])\n",
    "            line_count += 1\n",
    "        print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, label, peaks):\n",
    "    classesM = ['N', 'Ventricular', 'Paced', 'A', 'F', 'Noise']\n",
    "    predicted, result = predictByPart(data, peaks)\n",
    "    sumPredict = sum(predicted[x][1] for x in range(len(predicted)))\n",
    "    avgPredict = sumPredict / len(predicted)\n",
    "    print(\"The average of the predict is:\", avgPredict)\n",
    "    print(\"The most predicted label is {} with {:3.1f}% certainty\".format(classesM[avgPredict.argmax()],\n",
    "                                                                          100 * max(avgPredict[0])))\n",
    "    sec_idx = avgPredict.argsort()[0][-2]\n",
    "    print(\"The second predicted label is {} with {:3.1f}% certainty\".format(classesM[sec_idx],\n",
    "                                                                            100 * avgPredict[0][sec_idx]))\n",
    "    print(\"The original label of the record is \" + label)\n",
    "    print(\"Result:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPart(data, peaks):\n",
    "    classesM = ['N', 'Ventricular', 'Paced', 'A', 'F', 'Noise']\n",
    "    predicted = list()\n",
    "    result = \"\"\n",
    "    counter = [0] * len(classesM)\n",
    "\n",
    "    model = load_model('models/MLII-latest.hdf5')\n",
    "    \n",
    "    for i, peak in enumerate(peaks[3:-1]):\n",
    "        total_n = len(peaks)\n",
    "        start, end = peak - INPUT_SIZE // 2, peak + INPUT_SIZE // 2\n",
    "        prob = model.predict(data[:, start:end])\n",
    "        prob = prob[:, 0]\n",
    "        ann = np.argmax(prob)\n",
    "        counter[ann] += 1\n",
    "        if classesM[ann] != \"N\":\n",
    "            print(\"The {}/{}-record classified as {} with {:3.1f}% certainty\".format(i, total_n, classesM[ann], 100 * prob[0, ann]))\n",
    "        result += \"(\" + classesM[ann] + \":\" + str(round(100 * prob[0, ann], 1)) + \"%)\"\n",
    "        predicted.append([classesM[ann], prob])\n",
    "        if classesM[ann] != 'N' and prob[0, ann] > 0.95:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.plot(data[:, start:end][0, :, 0], )\n",
    "            mkdir_recursive('results')\n",
    "            plt.savefig('results/hazard-' + classesM[ann] + '.png', format=\"png\", dpi=300)\n",
    "            plt.close()\n",
    "    result += \"{}-N, {}-Venticular, {}-Paced, {}-A, {}-F, {}-Noise\".format(counter[0], counter[1], counter[2], counter[3], counter[4], counter[5])\n",
    "    return predicted, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8528 lines.\n",
      "The record of training2017/A06289.mat\n"
     ]
    }
   ],
   "source": [
    "data, label = cincData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "from sklearn import preprocessing\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    sr = 300\n",
    "    data = np.nan_to_num(data)  # removing NaNs and Infs\n",
    "    data = resample(data, int(len(data) * 360 / sr))  # resample to match the data sampling rate 360(mit), 300(cinc)\n",
    "    data = preprocessing.scale(data)\n",
    "    peaks, _ = find_peaks(data, distance=150)\n",
    "    data = data.reshape(1, len(data))\n",
    "    data = np.expand_dims(data, axis=2)  # required by Keras\n",
    "    return data, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, peaks = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3/55-record classified as Ventricular with 54.8% certainty\n",
      "The 9/55-record classified as A with 96.7% certainty\n",
      "The 13/55-record classified as A with 56.7% certainty\n",
      "The 18/55-record classified as A with 94.5% certainty\n",
      "The 19/55-record classified as A with 66.2% certainty\n",
      "The 23/55-record classified as Ventricular with 73.5% certainty\n",
      "The 24/55-record classified as A with 91.9% certainty\n",
      "The 29/55-record classified as A with 95.0% certainty\n",
      "The 34/55-record classified as A with 97.5% certainty\n",
      "The 38/55-record classified as Ventricular with 80.7% certainty\n",
      "The 39/55-record classified as A with 99.9% certainty\n",
      "The average of the predict is: [[8.0156213e-01 4.3196879e-02 3.9744085e-05 1.4795382e-01 6.9554383e-03\n",
      "  2.9192219e-04]]\n",
      "The most predicted label is N with 80.2% certainty\n",
      "The second predicted label is A with 14.8% certainty\n",
      "The original label of the record is O\n",
      "Result:\n",
      "(N:100.0%)(N:100.0%)(N:100.0%)(Ventricular:54.8%)(N:91.4%)(N:100.0%)(N:100.0%)(N:99.8%)(N:100.0%)(A:96.7%)(N:100.0%)(N:99.9%)(N:99.9%)(A:56.7%)(N:99.4%)(N:100.0%)(N:100.0%)(N:99.9%)(A:94.5%)(A:66.2%)(N:100.0%)(N:100.0%)(N:93.5%)(Ventricular:73.5%)(A:91.9%)(N:100.0%)(N:99.7%)(N:100.0%)(N:66.5%)(A:95.0%)(N:100.0%)(N:99.2%)(N:100.0%)(N:94.6%)(A:97.5%)(N:100.0%)(N:98.9%)(N:100.0%)(Ventricular:80.7%)(A:99.9%)(N:100.0%)(N:100.0%)(N:99.8%)(N:99.7%)(N:100.0%)(N:100.0%)(N:100.0%)(N:99.8%)(N:100.0%)(N:100.0%)(N:100.0%)40-N, 3-Venticular, 0-Paced, 8-A, 0-F, 0-Noise\n"
     ]
    }
   ],
   "source": [
    "predict(data, label, peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
